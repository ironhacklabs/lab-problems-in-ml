{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Over & Underfitting\n",
    "## Predicting Boston Housing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "In this project, you will use the Boston Housing Prices dataset to build several models to predict the prices of homes with particular qualities from the suburbs of Boston, MA.\n",
    "We will build models with several different parameters, which will change the goodness of fit for each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Exploration\n",
    "Since we want to predict the value of houses, the **target variable**, `'MEDV'`, will be the variable we seek to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and explore the data. Clean the data for outliers and missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>5.961</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>376.94</td>\n",
       "      <td>9.88</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10328</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>5.927</td>\n",
       "      <td>47.2</td>\n",
       "      <td>6.9320</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.22</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.34940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.972</td>\n",
       "      <td>76.7</td>\n",
       "      <td>3.1025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.24</td>\n",
       "      <td>9.97</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.73397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.597</td>\n",
       "      <td>94.9</td>\n",
       "      <td>1.5257</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>351.85</td>\n",
       "      <td>21.45</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04337</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>6.115</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.8147</td>\n",
       "      <td>4.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>393.97</td>\n",
       "      <td>9.43</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>9.32909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.185</td>\n",
       "      <td>98.7</td>\n",
       "      <td>2.2616</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.13</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>51.13580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597</td>\n",
       "      <td>5.757</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4130</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.60</td>\n",
       "      <td>10.11</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.01501</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401</td>\n",
       "      <td>7.923</td>\n",
       "      <td>24.8</td>\n",
       "      <td>5.8850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>395.52</td>\n",
       "      <td>3.16</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.02055</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>6.383</td>\n",
       "      <td>35.7</td>\n",
       "      <td>9.1876</td>\n",
       "      <td>2.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.77</td>\n",
       "      <td>24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.08244</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>6.481</td>\n",
       "      <td>18.5</td>\n",
       "      <td>6.1899</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>379.41</td>\n",
       "      <td>6.36</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         crim    zn  indus  chas    nox     rm    age     dis   rad    tax  \\\n",
       "0     0.15876   0.0  10.81   0.0  0.413  5.961   17.5  5.2873   4.0  305.0   \n",
       "1     0.10328  25.0   5.13   0.0  0.453  5.927   47.2  6.9320   8.0  284.0   \n",
       "2     0.34940   0.0   9.90   0.0  0.544  5.972   76.7  3.1025   4.0  304.0   \n",
       "3     2.73397   0.0  19.58   0.0  0.871  5.597   94.9  1.5257   5.0  403.0   \n",
       "4     0.04337  21.0   5.64   0.0  0.439  6.115   63.0  6.8147   4.0  243.0   \n",
       "..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
       "399   9.32909   0.0  18.10   0.0  0.713  6.185   98.7  2.2616  24.0  666.0   \n",
       "400  51.13580   0.0  18.10   0.0  0.597  5.757  100.0  1.4130  24.0  666.0   \n",
       "401   0.01501  90.0   1.21   1.0  0.401  7.923   24.8  5.8850   1.0  198.0   \n",
       "402   0.02055  85.0   0.74   0.0  0.410  6.383   35.7  9.1876   2.0  313.0   \n",
       "403   0.08244  30.0   4.93   0.0  0.428  6.481   18.5  6.1899   6.0  300.0   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       19.2  376.94   9.88  21.7  \n",
       "1       19.7  396.90   9.22  19.6  \n",
       "2       18.4  396.24   9.97  20.3  \n",
       "3       14.7  351.85  21.45  15.4  \n",
       "4       16.8  393.97   9.43  20.5  \n",
       "..       ...     ...    ...   ...  \n",
       "399     20.2  396.90  18.13  14.1  \n",
       "400     20.2    2.60  10.11  15.0  \n",
       "401     13.6  395.52   3.16  50.0  \n",
       "402     17.3  396.90   5.77  24.7  \n",
       "403     16.6  379.41   6.36  23.7  \n",
       "\n",
       "[404 rows x 14 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('../data/boston_data.csv')\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.00000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.730912</td>\n",
       "      <td>10.509901</td>\n",
       "      <td>11.189901</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>6.30145</td>\n",
       "      <td>68.601733</td>\n",
       "      <td>3.799666</td>\n",
       "      <td>9.836634</td>\n",
       "      <td>411.688119</td>\n",
       "      <td>18.444554</td>\n",
       "      <td>355.068243</td>\n",
       "      <td>12.598936</td>\n",
       "      <td>22.312376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.943922</td>\n",
       "      <td>22.053733</td>\n",
       "      <td>6.814909</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.117321</td>\n",
       "      <td>0.67583</td>\n",
       "      <td>28.066143</td>\n",
       "      <td>2.109916</td>\n",
       "      <td>8.834741</td>\n",
       "      <td>171.073553</td>\n",
       "      <td>2.150295</td>\n",
       "      <td>94.489572</td>\n",
       "      <td>6.925173</td>\n",
       "      <td>8.837019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.169100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.90275</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>2.087875</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>17.375000</td>\n",
       "      <td>374.710000</td>\n",
       "      <td>7.135000</td>\n",
       "      <td>17.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.253715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.795000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.23050</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>391.065000</td>\n",
       "      <td>11.265000</td>\n",
       "      <td>21.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.053158</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.62925</td>\n",
       "      <td>94.150000</td>\n",
       "      <td>5.222125</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.007500</td>\n",
       "      <td>16.910000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.78000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>34.370000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox         rm  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.00000   \n",
       "mean     3.730912   10.509901   11.189901    0.069307    0.556710    6.30145   \n",
       "std      8.943922   22.053733    6.814909    0.254290    0.117321    0.67583   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.392000    3.56100   \n",
       "25%      0.082382    0.000000    5.190000    0.000000    0.453000    5.90275   \n",
       "50%      0.253715    0.000000    9.795000    0.000000    0.538000    6.23050   \n",
       "75%      4.053158   12.500000   18.100000    0.000000    0.631000    6.62925   \n",
       "max     88.976200   95.000000   27.740000    1.000000    0.871000    8.78000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    68.601733    3.799666    9.836634  411.688119   18.444554  355.068243   \n",
       "std     28.066143    2.109916    8.834741  171.073553    2.150295   94.489572   \n",
       "min      2.900000    1.169100    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.800000    2.087875    4.000000  281.000000   17.375000  374.710000   \n",
       "50%     76.600000    3.207450    5.000000  330.000000   19.000000  391.065000   \n",
       "75%     94.150000    5.222125   24.000000  666.000000   20.200000  396.007500   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  404.000000  404.000000  \n",
       "mean    12.598936   22.312376  \n",
       "std      6.925173    8.837019  \n",
       "min      1.730000    5.000000  \n",
       "25%      7.135000   17.100000  \n",
       "50%     11.265000   21.400000  \n",
       "75%     16.910000   25.000000  \n",
       "max     34.370000   50.000000  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.isnull().sum() # No missing values\n",
    "boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we want to explore the data. Pick several varibables you think will be ost correlated with the prices of homes in Boston, and create plots that show the data dispersion as well as the regression line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(12,12))\n",
    "\n",
    "sns.regplot('crim', 'medv', data=boston, ax = axs[0,0], order =3)\n",
    "sns.regplot('rm', 'medv', data=boston, ax = axs[0,1])\n",
    "sns.regplot('black', 'medv', data=boston, ax = axs[1,0], order = 3)\n",
    "sns.regplot('lstat', 'medv', data=boston, ax = axs[1,1], order =3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do these plots tell you about the relationships between these variables and the prices of homes in Boston? Are these the relationships you expected to see in these variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Rooms and Population status are clearly correlated to the housing price ( I expected this). Number of rooms seems fairly linear status not so much (it seems to have less impact as the status increases, which would be kind of expected).\n",
    "\n",
    "##### For the crime rate, it seems to have an impact, with the price decreasing upto a point then there are very few samples for higher rates, so not representative.\n",
    "\n",
    "##### For % of black people,I donÂ´t see what I expected - concentration of lower prices where % of blacks is higher. The vast majority of points are at the top of the scale and dist. is all over the place for those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a heatmap of the remaining variables. Are there any variables that you did not consider that have very high correlations? What are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INDUS, NOX, Age, Tax, Pt Ratio seems to have some negative correlation also with the price. (Actually I plotted some of them and donÂ´t see that much of a relation in terms of a x/y curve...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (12,12))\n",
    "sns.heatmap(boston.corr(method='spearman'),annot = True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Statistics\n",
    "Calculate descriptive statistics for housing price. Include the minimum, maximum, mean, median, and standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.medv.describe())\n",
    "print('median:',boston.medv.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Developing a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Define a Performance Metric\n",
    "What is the performance meteric with which you will determine the performance of your model? Create a function that calculates this performance metric, and then returns the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    return r2_score(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Shuffle and Split Data\n",
    "Split the data into the testing and training datasets. Shuffle the data as well to remove any bias in selecting the traing and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(boston.iloc[:,:-1])\n",
    "y = np.array(boston.iloc[:,-1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Analyzing Model Performance\n",
    "Next, we are going to build a Random Forest Regressor, and test its performance with several different parameter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves\n",
    "Lets build the different models. Set the max_depth parameter to 2, 4, 6, 8, and 10 respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr_models =[]\n",
    "\n",
    "for p in [2,4,6,8,10]: rfr_models.append(RandomForestRegressor(max_depth=p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the score for each tree on the training set and on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_scores = []\n",
    "y_pred_test_scores = []\n",
    "\n",
    "for i,p in enumerate([2,4,6,8,10]):\n",
    "    rfr = rfr_models[i]\n",
    "    rfr.fit(X_train, y_train)\n",
    "    y_pred_train=rfr.predict(X_train)\n",
    "    y_pred_test = rfr.predict(X_test)\n",
    "    y_pred_train_scores.append(performance_metric(y_train, y_pred_train))\n",
    "    y_pred_test_scores.append(performance_metric(y_test, y_pred_test))\n",
    "\n",
    "plt.plot([2,4,6,8,10],y_pred_train_scores,label='train')\n",
    "plt.plot([2,4,6,8,10],y_pred_test_scores,label='test')\n",
    "plt.xticks([2,4,6,8,10])\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('r2score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these results tell you about the effect of the depth of the trees on the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Given the results, increasing the depth improves the training result up to a point. From depth 8 to 10 we can see that the test result worsens, which means at this point we are starting to overfit the model. It would actually be more beneficial to choose max_depth = 8 in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Tradeoff\n",
    "When the model is trained with a maximum depth of 1, does the model suffer from high bias or from high variance? How about when the model is trained with a maximum depth of 10?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### with maximum_depth=1 the model suffers from high bias (the model is not complex enough to fully \"interpret\" the data. With maximum_depth = 10 the model has high variance, the models is too complex ending up \"over interpreting \" the data and overfitting the training data, and not generalizing well --> test results are worse than for max_depth = 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best-Guess Optimal Model\n",
    "What is the max_depth parameter that you think would optimize the model? Run your model and explain its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_scores = []\n",
    "y_pred_test_scores = []\n",
    "\n",
    "depths = np.arange(1,11,1)\n",
    "\n",
    "for p in depths:\n",
    "    rfr = RandomForestRegressor(max_depth=p)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    y_pred_train=rfr.predict(X_train)\n",
    "    y_pred_test = rfr.predict(X_test)\n",
    "    y_pred_train_scores.append(performance_metric(y_train, y_pred_train))\n",
    "    y_pred_test_scores.append(performance_metric(y_test, y_pred_test))\n",
    "\n",
    "plt.plot(depths,y_pred_train_scores,label='train')\n",
    "plt.plot(depths,y_pred_test_scores,label='test')\n",
    "plt.xlabel('max_depth')\n",
    "plt.xticks(depths)\n",
    "plt.ylabel('r2score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The results vary with each run ... I dontÂ´know why since the test train split has random state fixed!? But anyway with the result above the best scenario would be for max_depth = 8 since with provides the highest test score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicability\n",
    "*In a few sentences, discuss whether the constructed model should or should not be used in a real-world setting.*  \n",
    "**Hint:** Some questions to answering:\n",
    "- *How relevant today is data that was collected from 1978?*\n",
    "- *Are the features present in the data sufficient to describe a home?*\n",
    "- *Is the model robust enough to make consistent predictions?*\n",
    "- *Would data collected in an urban city like Boston be applicable in a rural city?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data that is more than 40 years old should not be used in predicting house values which varies a lot in time due to speculation, inflation. There seems to be some variation in test results, but overall the r2_score is pretty consistent above 0.80 suggesting some robustness if max_depth>3. So it should provide some degree of confidence in the results if waht we were trying to predict was the housing price in 1978. I would prefer a dataset with more data also (more rows). This would be good for Boston, donÂ´t think it would apply to differently stratified towns or rural cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
